{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worch vs Torch: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import worch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_grad_enabled(False)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_weights(wnet, tnet):\n",
    "    j = 0\n",
    "    i = 1\n",
    "    while j < len(wnet.module_list):\n",
    "        ww = wnet[j].params[0]\n",
    "        wb = wnet[j].params[1]\n",
    "        tw = tnet[j].weight\n",
    "        tb = tnet[j].bias\n",
    "        if not ww.allclose(tw):\n",
    "            return f'weight{i}', ww, tw\n",
    "        if not wb.allclose(tb):\n",
    "            return f'bias{i}', wb, tb\n",
    "        i += 1\n",
    "        j += 2\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_gradients(wnet, tnet):\n",
    "    j = len(wnet.module_list)-1\n",
    "    i = 1\n",
    "    while j < len(wnet.module_list):\n",
    "        ww = wnet[j].params[0].grad\n",
    "        wb = wnet[j].params[1].grad\n",
    "        tw = tnet[j].weight.grad\n",
    "        tb = tnet[j].bias.grad\n",
    "        if not ww.allclose(tw):\n",
    "            return f'weight{i}', ww, tw\n",
    "        if not wb.allclose(tb):\n",
    "            return f'bias{i}', wb, tb\n",
    "        i += 1\n",
    "        j += 2\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_worch(model, x, y, criterion, optimizer):\n",
    "    model.train()\n",
    "    yp = model(x)\n",
    "    loss = criterion(yp, y)\n",
    "    optimizer.zero_grad()\n",
    "    criterion.backward() # call on module not tensor\n",
    "    optimizer.step()\n",
    "    return loss.cpu().detach().item(), yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_torch(model, x, y, criterion, optimizer):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    yp = model(x)\n",
    "    loss = criterion(yp, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    torch.set_grad_enabled(False)\n",
    "    return loss.cpu().detach().item(), yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, x, y, criterion):\n",
    "    model.eval()\n",
    "    yp = model(x)\n",
    "    loss = criterion(yp, y)\n",
    "    return loss.cpu().detach().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.n_samples = 15000\n",
    "        self.n_features = 72\n",
    "        self.n_targets = 3\n",
    "        self.n_test = 0.2\n",
    "        self.n_val = 0.2\n",
    "        self.n_epochs = 250\n",
    "        self.batch_size = 72\n",
    "        self.lr = 0.02\n",
    "        self.hidden_sizes = [self.n_features, 32, 8, self.n_targets]\n",
    "        self.init_as_torch = False\n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = datasets.make_regression(n_samples=opt.n_samples,\n",
    "                                n_features=opt.n_features,\n",
    "                                n_targets=opt.n_targets,\n",
    "                                noise=35,\n",
    "                                bias=0.2568541)\n",
    "X_, X_test, Y_, Y_test = train_test_split(\n",
    "    X, Y, test_size=opt.n_test, shuffle=True\n",
    ")\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_, Y_, test_size=opt.n_val, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_torch(x):\n",
    "    return torch.from_numpy(x).float().requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(X_)\n",
    "X_train = make_torch(sc.transform(X_train))\n",
    "Y_train = make_torch(Y_train)/100\n",
    "X_val = make_torch(sc.transform(X_val))\n",
    "Y_val = make_torch(Y_val)/100\n",
    "X_test = make_torch(sc.transform(X_test))\n",
    "Y_test = make_torch(Y_test)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9600, 72]), torch.Size([9600, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=72, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmodules = []\n",
    "tmodules = []\n",
    "for i in range(len(opt.hidden_sizes[1:])):\n",
    "    wmod = [worch.nn.Linear(opt.hidden_sizes[i], opt.hidden_sizes[i+1])]\n",
    "    tmod = [torch.nn.Linear(opt.hidden_sizes[i], opt.hidden_sizes[i+1])]\n",
    "    if opt.init_as_torch:\n",
    "        wmod[-1].params[0] = tmod[-1].state_dict()['weight'].clone()\n",
    "        wmod[-1].params[1] = tmod[-1].state_dict()['bias'].clone()\n",
    "    if i < len(opt.hidden_sizes)-2:\n",
    "        wmod.append(worch.nn.ReLU())\n",
    "        tmod.append(torch.nn.ReLU())\n",
    "    wmodules.extend(wmod)\n",
    "    tmodules.extend(tmod)\n",
    "wnet = worch.nn.Sequential(*wmodules)\n",
    "tnet = torch.nn.Sequential(*tmodules)\n",
    "tnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear 0\n",
      "wwstd tensor(0.1363)\n",
      "twstd tensor(0.0673)\n",
      "wwmean tensor(0.0033)\n",
      "twmean tensor(0.0008)\n",
      "wbstd tensor(0.2319)\n",
      "tbstd tensor(0.0750)\n",
      "wbmean tensor(0.0300)\n",
      "tbmean tensor(-0.0105)\n",
      "same weight False\n",
      "same bias False\n",
      "\n",
      "Linear 2\n",
      "wwstd tensor(0.2257)\n",
      "twstd tensor(0.1015)\n",
      "wwmean tensor(0.0099)\n",
      "twmean tensor(0.0008)\n",
      "wbstd tensor(0.4729)\n",
      "tbstd tensor(0.0793)\n",
      "wbmean tensor(-0.0275)\n",
      "tbmean tensor(-0.0362)\n",
      "same weight False\n",
      "same bias False\n",
      "\n",
      "Linear 4\n",
      "wwstd tensor(0.4324)\n",
      "twstd tensor(0.2116)\n",
      "wwmean tensor(0.0833)\n",
      "twmean tensor(0.0389)\n",
      "wbstd tensor(0.6613)\n",
      "tbstd tensor(0.0844)\n",
      "wbmean tensor(-0.2198)\n",
      "tbmean tensor(-0.2375)\n",
      "same weight False\n",
      "same bias False\n",
      "\n",
      "Linear 6\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "while True:\n",
    "    try:\n",
    "        print('Linear',j)\n",
    "        print('wwstd',wnet[j].params[0].std())\n",
    "        print('twstd',tnet[j].weight.std())\n",
    "        print('wwmean',wnet[j].params[0].mean())\n",
    "        print('twmean',tnet[j].weight.mean())\n",
    "        print('wbstd',wnet[j].params[1].std())\n",
    "        print('tbstd',tnet[j].bias.std())\n",
    "        print('wbmean',wnet[j].params[1].mean())      \n",
    "        print('tbmean',tnet[j].bias.mean())\n",
    "        print('same weight', wnet[j].params[0].allclose(tnet[j].weight))\n",
    "        print('same bias', wnet[j].params[1].allclose(tnet[j].bias))\n",
    "        j += 2\n",
    "        print()\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcrit = worch.nn.MSELoss()\n",
    "wcrit.register_previous_module(wnet)\n",
    "tcrit = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "woptim = worch.optim.SGD(wnet.parameters(), lr=opt.lr)\n",
    "toptim = torch.optim.SGD(tnet.parameters(), lr=opt.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch@(1/250)] train: 3.54221773147583, val: 2.5386977195739746\n",
      "[worch@(1/250)] train: 1.0950359106063843, val: 0.32036903500556946\n",
      "-\n",
      "[torch@(100/250)] train: 0.1171184778213501, val: 0.13379694521427155\n",
      "[worch@(100/250)] train: 0.12081274390220642, val: 0.14609786868095398\n",
      "-\n",
      "[torch@(200/250)] train: 0.11366958171129227, val: 0.1350567638874054\n",
      "[worch@(200/250)] train: 0.11839313060045242, val: 0.148220494389534\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "w_trlosses = []\n",
    "w_valosses = []\n",
    "t_trlosses = []\n",
    "t_valosses = []\n",
    "j = 0\n",
    "for epoch in range(1, opt.n_epochs+1):\n",
    "    # Train\n",
    "    wnet.train()\n",
    "    tnet.train()\n",
    "    wlosses = []\n",
    "    tlosses = []\n",
    "    for k, b in enumerate(range(0, X_train.shape[0], opt.batch_size)):\n",
    "        x = X_train[b:b+opt.batch_size]\n",
    "        y = Y_train[b:b+opt.batch_size]\n",
    "        wloss, wyp = train_worch(wnet, x.clone(), \n",
    "                                 y.clone(), wcrit, \n",
    "                                 woptim)\n",
    "        tloss, typ = train_torch(tnet, x.clone(), \n",
    "                                 y.clone(), tcrit, \n",
    "                                 toptim)\n",
    "        wlosses.append(wloss)\n",
    "        tlosses.append(tloss)\n",
    "    w_trlosses.append(torch.mean(torch.Tensor(wlosses)))\n",
    "    t_trlosses.append(torch.mean(torch.Tensor(tlosses)))\n",
    "    # Val\n",
    "    wnet.eval()\n",
    "    tnet.eval()\n",
    "    wlosses = []\n",
    "    tlosses = []\n",
    "    for b in range(0, X_test.shape[0], opt.batch_size):\n",
    "        x = X_test[b:b+opt.batch_size]\n",
    "        y = Y_test[b:b+opt.batch_size]\n",
    "        wloss = eval_model(wnet, x, y, wcrit)\n",
    "        tloss = eval_model(tnet, x, y, tcrit)\n",
    "        wlosses.append(wloss)\n",
    "        tlosses.append(tloss)\n",
    "    w_valosses.append(torch.mean(torch.Tensor(wlosses)))\n",
    "    t_valosses.append(torch.mean(torch.Tensor(tlosses)))\n",
    "    if epoch==1 or epoch % 100 == 0:\n",
    "        print('[torch@({}/{})] train: {}, val: {}'.format(\n",
    "            epoch, opt.n_epochs, t_trlosses[-1], t_valosses[-1]\n",
    "        ))\n",
    "        print('[worch@({}/{})] train: {}, val: {}\\n-'.format(\n",
    "            epoch, opt.n_epochs, w_trlosses[-1], w_valosses[-1]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = torch.arange(opt.n_epochs)\n",
    "plt.plot(n, w_trlosses, 'r', label='worch train')\n",
    "plt.plot(n, w_valosses, 'k-', label='worch val')\n",
    "plt.plot(n, t_trlosses, 'g', label='torch train')\n",
    "plt.plot(n, t_valosses, 'b-', label='torch val')\n",
    "plt.legend()\n",
    "plt.rcParams['figure.figsize'] = (14,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_trlosses = []\n",
    "w_valosses = []\n",
    "t_trlosses = []\n",
    "t_valosses = []\n",
    "j = 0\n",
    "# opt.n_epochs = 1\n",
    "for epoch in range(1, opt.n_epochs+1):\n",
    "#     print('epoch',epoch)\n",
    "    # Train\n",
    "    wnet.train()\n",
    "    tnet.train()\n",
    "    wlosses = []\n",
    "    tlosses = []\n",
    "    for k, b in enumerate(range(0, X_train.shape[0], opt.batch_size)):\n",
    "    #     b = 10\n",
    "    #     k = 1\n",
    "        x = X_train[b:b+opt.batch_size]\n",
    "        y = Y_train[b:b+opt.batch_size]\n",
    "        # Debug ...\n",
    "        if opt.init_as_torch:\n",
    "            res = compare_weights(wnet, tnet)\n",
    "#             if res is not None:\n",
    "#                 print('WEIGHTS')\n",
    "#                 print('batch', k, '/', X_train.shape[0]//opt.batch_size)\n",
    "#                 print('x,y', x.shape, y.shape)\n",
    "#                 print(res[0])\n",
    "#                 print('worch:')\n",
    "#                 print(res[1].shape)\n",
    "#                 print(res[1])\n",
    "#                 print('torch:')\n",
    "#                 print(res[2].shape)\n",
    "#                 print(res[2])\n",
    "#                 _ = input()\n",
    "#             else:\n",
    "#                 print('WEIGHTS OK')\n",
    "    #         wloss, wyp = train_worch(wnet, x.clone(), \n",
    "    #                                  y.clone(), wcrit, \n",
    "    #                                  woptim)\n",
    "    #         tloss, typ = train_torch(tnet, x.clone(), \n",
    "    #                                  y.clone(), tcrit, \n",
    "    #                                  toptim)\n",
    "        # Debug\n",
    "    #     ww = wnet[-1].params[0].grad.clone()\n",
    "    #     tw = tnet[-1].weight.detach().grad.clone()\n",
    "    #     print(ww, tw)\n",
    "        # WORCH\n",
    "        wyp = wnet(x)\n",
    "        wwloss = wcrit(wyp, y)\n",
    "        woptim.zero_grad()\n",
    "        wcrit.backward() # call on module not tensor\n",
    "        woptim.step()\n",
    "        wloss = wwloss.cpu().detach().item()\n",
    "        # TORCH\n",
    "        torch.set_grad_enabled(True)\n",
    "        typ = tnet(x)\n",
    "        ttloss = tcrit(typ, y)\n",
    "        toptim.zero_grad()\n",
    "        ttloss.backward()\n",
    "        toptim.step()\n",
    "        torch.set_grad_enabled(False)\n",
    "        tloss = ttloss.cpu().detach().item()\n",
    "#         # Debug\n",
    "#         ww = wnet[-1].params[0].grad.clone()\n",
    "# #         print('ww',ww)\n",
    "#         tw = tnet[-1].weight.grad.clone()\n",
    "#         wb = wnet[-1].params[1].grad.clone()\n",
    "#         tb = tnet[-1].bias.grad.clone()\n",
    "        # Debug\n",
    "#         if opt.init_as_torch:\n",
    "#             if not wyp.allclose(typ):\n",
    "#                 print('OUTPUT')\n",
    "#                 print('batch', k, '/', X_train.shape[0]//opt.batch_size)\n",
    "#                 print('x,y', x.shape, y.shape)\n",
    "#                 print('worch:')\n",
    "#                 print(wyp.shape)\n",
    "#                 print(wyp)\n",
    "#                 print('torch:')\n",
    "#                 print(typ.shape)\n",
    "#                 print(typ)\n",
    "#             else:\n",
    "#                 print('OUPTUT OK')\n",
    "        # Debug ...\n",
    "#         if opt.init_as_torch:\n",
    "#             res = compare_gradients(wnet, tnet)\n",
    "#             if res is not None:\n",
    "#                 print('GRAD')\n",
    "#                 print('batch', k, '/', X_train.shape[0]//opt.batch_size)\n",
    "#                 print('x,y', x.shape, y.shape)\n",
    "#                 print(res[0])\n",
    "#                 print('worch:')\n",
    "#                 print(res[1].shape)\n",
    "#                 print(res[1])\n",
    "#                 print('torch:')\n",
    "#                 print(res[2].shape)\n",
    "#                 print(res[2])\n",
    "#             else:\n",
    "#                 print('GRAD OK')\n",
    "        wlosses.append(wloss)\n",
    "        tlosses.append(tloss)\n",
    "    w_trlosses.append(torch.mean(torch.Tensor(wlosses)))\n",
    "    t_trlosses.append(torch.mean(torch.Tensor(tlosses)))\n",
    "    # Val\n",
    "#     wlosses = []\n",
    "#     tlosses = []\n",
    "#     for b in range(0, X_train.shape[0], opt.batch_size):\n",
    "#         x = X_train[b:b+opt.batch_size]\n",
    "#         y = Y_train[b:b+opt.batch_size]\n",
    "#         wloss = eval_model(wnet, x, y, wcrit)\n",
    "#         tloss = eval_model(tnet, x, y, tcrit)\n",
    "#         wlosses.append(wloss)\n",
    "#         tlosses.append(tloss)\n",
    "#     w_valosses.append(torch.mean(torch.Tensor(wlosses)))\n",
    "#     t_valosses.append(torch.mean(torch.Tensor(tlosses)))\n",
    "    if epoch==1 or epoch % 100 == 0:\n",
    "        t_valosses = ['prout']\n",
    "        w_valosses = ['prout']\n",
    "        print('[torch@({}/{})] train: {}, val: {}'.format(\n",
    "            epoch, opt.n_epochs, t_trlosses[-1], t_valosses[-1]\n",
    "        ))\n",
    "        print('[worch@({}/{})] train: {}, val: {}\\n-'.format(\n",
    "            epoch, opt.n_epochs, w_trlosses[-1], w_valosses[-1]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = len(wnet.module_list)\n",
    "wnet.module_list\n",
    "last_input = X_train[b:b+opt.batch_size]\n",
    "for i in range(j-2):\n",
    "    last_input = wnet[i](last_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttloss, wwloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyp.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss = (wyp-y)*0.5\n",
    "torch.mm(gloss.T, last_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww, tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb, tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb / tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5*0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.375*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.arange(x.shape[0]), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnet.training, wcrit.training, tnet.training, tcrit.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnet[0].training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:epfl-cs433]",
   "language": "python",
   "name": "conda-env-epfl-cs433-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
