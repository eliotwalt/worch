{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worch vs Torch: Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import worch\n",
    "from worch import nn\n",
    "from worch import optim\n",
    "from test_utils import generate_data\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_grad_enabled(False)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Forward (YES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty((2, 2)).normal_()\n",
    "y = torch.empty((2, 2)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfc = worch.nn.Linear(x.shape[1], 10)\n",
    "tfc = torch.nn.Linear(x.shape[1], 10)\n",
    "p = tfc.state_dict()\n",
    "wfc.params[0].shape == p['weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfc.params[0] = p['weight']\n",
    "wfc.params[1] = p['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(wfc(x)).allclose(tfc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(wfc(x)-tfc(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Backward (YES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[1, 2, 3],\n",
    "                  [3, 4, 2]])\n",
    "y_ = torch.ones((x.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfc = worch.nn.Linear(x.shape[1], 1)\n",
    "tfc = torch.nn.Linear(x.shape[1], 1)\n",
    "p = tfc.state_dict()\n",
    "wfc.params[0] = p['weight']\n",
    "wfc.params[1] = p['bias']\n",
    "wc = worch.nn.MSELoss()\n",
    "wc.register_previous_module(wfc)\n",
    "tc = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8032, -1.0905, -0.6042]]), tensor([-0.2874]), tensor(0.1348))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Worch\n",
    "y_worch = wfc(x)\n",
    "loss_worch = wc(y_worch, y_)\n",
    "wc.backward()\n",
    "wfc.params[0].grad, wfc.params[1].grad, loss_worch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.6064, -2.1811, -1.2083]]),\n",
       " tensor([-0.5747]),\n",
       " tensor(0.1348, grad_fn=<MseLossBackward>))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch\n",
    "torch.set_grad_enabled(True)\n",
    "x_torch = x.clone()\n",
    "x_torch.requires_grad_(True)\n",
    "y_torch = tfc(x_torch)\n",
    "loss_torch = tc(y_torch, y_)\n",
    "torch.set_grad_enabled(False)\n",
    "loss_torch.backward()\n",
    "tfc.weight.grad, tfc.bias.grad, loss_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU Forward (YES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty((2, 2)).normal_()\n",
    "y = torch.empty((2, 2)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(worch.nn.ReLU()(x)).allclose(torch.nn.ReLU()(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(worch.nn.ReLU()(x)-torch.nn.ReLU()(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU Backward (YES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0582, -0.5564],\n",
       "        [-1.2003, -0.5015]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0582, 0.0000],\n",
       "        [0.0000, 0.0000]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Worch\n",
    "wrelu = worch.nn.ReLU()\n",
    "b = wrelu(x)\n",
    "wrelu.backward(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0582, 0.0000],\n",
       "        [0.0000, 0.0000]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch\n",
    "torch.set_grad_enabled(True)\n",
    "trelu = torch.nn.ReLU()\n",
    "x_torch = x.clone()\n",
    "x_torch.requires_grad_(True)\n",
    "b = trelu(x_torch)\n",
    "b.backward(x_torch)\n",
    "x_torch.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Forward (YES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty((2, 2)).normal_()\n",
    "y = torch.empty((2, 2)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(worch.nn.Sigmoid()(x)).allclose(torch.nn.Sigmoid()(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(worch.nn.Sigmoid()(x)-torch.nn.Sigmoid()(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Backward (NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3085,  0.7158],\n",
       "        [-0.3074,  1.4279]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1034, 0.1481],\n",
       "        [0.1035, 0.1258]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Worch\n",
    "wsig = worch.nn.Sigmoid()\n",
    "b = wsig(x)\n",
    "wsig.backward(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0753,  0.1579],\n",
       "        [-0.0751,  0.2228]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch\n",
    "torch.set_grad_enabled(True)\n",
    "tsig = torch.nn.Sigmoid()\n",
    "x_torch = x.clone()\n",
    "x_torch.requires_grad_(True)\n",
    "b = tsig(x_torch)\n",
    "b.backward(x_torch)\n",
    "x_torch.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanh Forward (YES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty((2, 2)).normal_()\n",
    "y = torch.empty((2, 2)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(worch.nn.Tanh()(x)).allclose(torch.nn.Tanh()(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1921e-07)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(worch.nn.Tanh()(x)-torch.nn.Tanh()(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanh Backward (NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4869, -1.6125],\n",
       "        [ 1.0155, -0.9902]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1670, -0.1358],\n",
       "        [ 0.3150, -0.3229]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Worch\n",
    "wtgh = worch.nn.Tanh()\n",
    "b = wtgh(x)\n",
    "wtgh.backward(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2751, -0.2372],\n",
       "        [ 0.4165, -0.4221]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch\n",
    "torch.set_grad_enabled(True)\n",
    "tgh = torch.nn.Tanh()\n",
    "x_torch = x.clone()\n",
    "x_torch.requires_grad_(True)\n",
    "b = tgh(x_torch)\n",
    "b.backward(x_torch)\n",
    "x_torch.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE Forward (YES)\n",
    "like pytorch for comparison `mse = mean((input-target)**2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty((2, 2)).normal_()\n",
    "y = torch.empty((2, 2)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(worch.nn.MSELoss()(x, y)).allclose(torch.nn.MSELoss()(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(worch.nn.MSELoss()(x, y)-torch.nn.MSELoss()(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE Backward (YES)\n",
    "like pytorch for comparison `g = (input-target)*0.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2213,  1.2161],\n",
       "         [ 0.3322, -0.7773]]),\n",
       " tensor([[ 0.4168, -0.2098],\n",
       "         [ 1.5163, -0.3114]]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3191,  0.7130],\n",
       "        [-0.5921, -0.2330]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Worch\n",
    "wc = worch.nn.MSELoss()\n",
    "b = wc(x, y)\n",
    "g = wc.backward()\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3191,  0.7130],\n",
       "        [-0.5921, -0.2330]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch\n",
    "torch.set_grad_enabled(True)\n",
    "tc = torch.nn.MSELoss()\n",
    "x_torch = x.clone()\n",
    "x_torch.requires_grad_(True)\n",
    "b = tc(x_torch, y)\n",
    "b.backward()\n",
    "torch.set_grad_enabled(False)\n",
    "x_torch.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Forward (YES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty((2, 2)).normal_()\n",
    "y = torch.empty((2, 2)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfc1 = worch.nn.Linear(x.shape[1], 10)\n",
    "tfc1 = torch.nn.Linear(x.shape[1], 10)\n",
    "p = tfc1.state_dict()\n",
    "wfc1.params[0] = p['weight'].clone()\n",
    "wfc1.params[1]=p['bias'].clone()\n",
    "wfc2 = worch.nn.Linear(10, y.shape[1])\n",
    "tfc2 = torch.nn.Linear(10, y.shape[1])\n",
    "p = tfc2.state_dict()\n",
    "wfc2.params[0] = p['weight'].clone()\n",
    "wfc2.params[1]=p['bias'].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnet =  worch.nn.Sequential(\n",
    "    wfc1,\n",
    "    worch.nn.ReLU(),\n",
    "    wfc2,\n",
    ")\n",
    "tnet =  torch.nn.Sequential(\n",
    "    tfc1,\n",
    "    torch.nn.ReLU(),\n",
    "    tfc2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(wnet(x)).allclose(tnet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(wnet(x)-tnet(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Backward (YES)\n",
    "Cells must be run the exact same number of times because of accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2701,  0.4139],\n",
       "         [-0.5171,  0.9391]]),\n",
       " tensor([[ 0.6209,  0.6340],\n",
       "         [ 1.3865, -0.7368]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worch\n",
    "wc = worch.nn.MSELoss()\n",
    "wc.register_previous_module(wnet)\n",
    "y_worch = wnet(x)\n",
    "loss_worch = wc(y_worch, y)\n",
    "wgl = wc.backward()\n",
    "wgw0 = wnet[0].params[0].grad\n",
    "wgb0 = wnet[0].params[1].grad\n",
    "wgw1 = wnet[2].params[0].grad\n",
    "wgb1 = wnet[2].params[1].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "tc = torch.nn.MSELoss()\n",
    "torch.set_grad_enabled(True)\n",
    "x_torch = x.clone()\n",
    "x_torch.requires_grad_(True)\n",
    "y_torch = tnet(x_torch)\n",
    "loss_torch = tc(y_torch, y)\n",
    "torch.set_grad_enabled(False)\n",
    "tgl = loss_torch.backward()\n",
    "tgw0 = tnet[0].weight.grad\n",
    "tgb0 = tnet[0].bias.grad\n",
    "tgw1 = tnet[2].weight.grad\n",
    "tgb1 = tnet[2].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgb1.allclose(wgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgw1.allclose(wgw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgb0.allclose(wgb0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgw0.allclose(wgw0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1050, -0.1609],\n",
       "        [-1.6591,  2.8551],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.4068, -0.7835],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.8720, -1.4602],\n",
       "        [ 0.0000,  0.0000]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgw0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD (YES)\n",
    "Cells must be run the exact same number of times because of sgd updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty((2, 2)).normal_()\n",
    "y = torch.empty((2, 2)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusing network above\n",
    "wsgd = worch.optim.SGD(wnet.parameters(), lr=0.01)\n",
    "tsgd = torch.optim.SGD(tnet.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worch\n",
    "wc = worch.nn.MSELoss()\n",
    "wc.register_previous_module(wnet)\n",
    "y_worch = wnet(x)\n",
    "loss_worch = wc(y_worch, y)\n",
    "wsgd.zero_grad()\n",
    "wc.backward()\n",
    "wsgd.step()\n",
    "ww0 = wnet[0].params[0]\n",
    "wb0 = wnet[0].params[1]\n",
    "ww1 = wnet[2].params[0]\n",
    "wb1 = wnet[2].params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "tc = torch.nn.MSELoss()\n",
    "torch.set_grad_enabled(True)\n",
    "x_torch = x.clone()\n",
    "x_torch.requires_grad_(True)\n",
    "y_torch = tnet(x_torch)\n",
    "loss_torch = tc(y_torch, y)\n",
    "tsgd.zero_grad()\n",
    "loss_torch.backward()\n",
    "tsgd.step()\n",
    "torch.set_grad_enabled(False)\n",
    "tw0 = tnet[0].weight\n",
    "tb0 = tnet[0].bias\n",
    "tw1 = tnet[2].weight\n",
    "tb1 = tnet[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb1.allclose(wb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw1.allclose(ww1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw0.allclose(ww0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb0.allclose(wb0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:epfl-cs433]",
   "language": "python",
   "name": "conda-env-epfl-cs433-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
